# -*- coding: utf-8 -*-
"""fintech_CS3_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/140yRn9exEsd-PEeKQK-fCMsI4ly9NzPS

##Importing Libraries and dataset
"""

import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;
import seaborn as sns;
from dateutil import parser;
dataset=pd.read_csv("/content/drive/My Drive/Dataset/appdata10.csv");
print("Dataset Extracted");

"""##Dataset Description and Extracting"""

dataset.head()

dataset.describe()

#Data Cleaning
dataset.hour=dataset.hour.str.slice(1,3).astype(int);
num_dataset=dataset.drop(columns=['user','first_open','screen_list','enrolled','enrolled_date'],axis=1);
num_dataset.head()

"""##Data Visualization"""

sns.kdeplot(data=dataset.age,shade=True);

sns.scatterplot(x=dataset.age,y=dataset.numscreens,hue=dataset.enrolled);

plt.figure(figsize=(20,10));
plt.suptitle("Histogram of Numerical Values",fontsize=20);
for i in range(0,num_dataset.shape[1]):
  plt.subplot(2,4,i+1);
  f=plt.gca();
  f.set_title(num_dataset.columns[i]);
  vals=num_dataset.iloc[:,i].nunique();
  plt.hist(num_dataset.iloc[:,i],bins=vals);
plt.tight_layout(rect=[0,0.03,1,0.95]);
#plt.savefig('Histogram.jpg')

"""###Correlation with Target Variable"""

num_dataset.corrwith(dataset.enrolled).plot.bar(figsize=(12,8),fontsize=15,title="Correlation with Target Variable",rot=-45);

plt.figure(figsize=(10,8));
corr=num_dataset.corr();
mask=np.zeros_like(corr,dtype=np.bool);
mask[np.triu_indices_from(mask)]=True;
plt.title("Correlation Matrix");
sns.heatmap(corr,mask=mask,annot=True,center=0);
plt.xticks(rotation=-45);

"""##Feature Engineering

###Analysing Date Column
"""

date_dataset=dataset.copy()
date_dataset.dropna(inplace=True);
date_dataset.reset_index(inplace=True);
dataset.drop(columns=['first_open','enrolled_date'],axis=1,inplace=True);
date_dataset.drop(columns=dataset.columns,axis=1,inplace=True);
print(date_dataset.head());
print(date_dataset.dtypes);

date_dataset.first_open   =[parser.parse(row_data) for row_data in date_dataset.first_open];
date_dataset.enrolled_date=[parser.parse(row_data) for row_data in date_dataset.enrolled_date];
date_dataset['diff']=(date_dataset.enrolled_date-date_dataset.first_open).astype('timedelta64[h]');
print(date_dataset.head());
print(date_dataset.dtypes);

plt.figure(figsize=(20,5));
plt.suptitle("Histogram of Difference in time between enrolled time and first open(only premium users)",fontsize=15);
plt.subplot(1,3,1);
plt.hist(date_dataset['diff']);
plt.title("All Premium User");
plt.subplot(1,3,2);
plt.hist(date_dataset['diff'],range=(0,720));
plt.title("Premium User who enrolled within one month");
plt.subplot(1,3,3);
plt.hist(date_dataset['diff'],range=(0,48));
plt.title("Premium User who enrolled within two day");
plt.show();

premium_user=date_dataset.shape[0];
instant_user=len([i for i in range(0,premium_user) if date_dataset['diff'][i]==0]);
lazy_user=len([i for i in range(0,premium_user) if date_dataset['diff'][i]>48]);
print(str(round(100*instant_user/premium_user,1)) + "% Percentage of Premium User enrolled within one hour");
print(str(round(100*lazy_user/premium_user,1)) + "% Percentage of Premium User enrolled after 2 days");
plt.hist(date_dataset['diff'],range=(1,48));
plt.title("Premium User who Enrolled in atleast one and within 2 days");

"""###Analysing Screen"""

top_screen=pd.read_csv("/content/drive/My Drive/Dataset/top_screens.csv").top_screens.values;

#Mapping Screen to Fields
dataset.screen_list=dataset.screen_list.astype(str)+",";
for sc in top_screen:
  dataset[sc]=dataset.screen_list.str.contains(sc).astype(int);
  dataset.screen_list=dataset.screen_list.str.replace(sc+",","");
dataset['Other']=dataset.screen_list.str.count(",");
dataset.drop(columns=['screen_list'],axis=1,inplace=True);

#Funnels
savings_screens = ["Saving1", "Saving2", "Saving2Amount", "Saving4", "Saving5", "Saving6","Saving7", "Saving8", "Saving9", "Saving10"];
dataset['SavingCount']=dataset[savings_screens].sum(axis=1);
dataset.drop(columns=savings_screens,axis=1,inplace=True);
credit_screens = ["Credit1", "Credit2", "Credit3", "Credit3Container", "Credit3Dashboard"];
dataset['CreditCount']=dataset[credit_screens].sum(axis=1);
dataset.drop(columns=credit_screens,axis=1,inplace=True);
cc_screens = ["CC1", "CC1Category", "CC3"];
dataset['CCCount']=dataset[cc_screens].sum(axis=1);
dataset.drop(columns=cc_screens,axis=1,inplace=True);
loan_screens = ["Loan", "Loan2", "Loan3", "Loan4"];
dataset['LoanCount']=dataset[loan_screens].sum(axis=1);
dataset.drop(columns=loan_screens,axis=1,inplace=True);

"""##Final Dataset Preview and Extraction to new dataset"""

dataset.head()

dataset.shape

dataset.describe()

dataset.to_csv("new_appdata10.csv",index=False);